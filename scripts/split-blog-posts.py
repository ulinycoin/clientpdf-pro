#!/usr/bin/env python3

"""
Script to split blogPosts.ts into separate files by language
This optimizes mobile performance by enabling lazy loading
"""

import os
import re
from datetime import datetime

SOURCE_FILE = os.path.join(os.path.dirname(__file__), '../src/data/blogPosts.ts.backup')
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), '../src/data/blogPosts')

print('üì¶ Splitting blog posts by language (Python version)...\n')

# Read source file
with open(SOURCE_FILE, 'r', encoding='utf-8') as f:
    content = f.read()

# Find the array content
match = re.search(r'const blogPostsData: BlogPost\[\] = \[(.*)\];', content, re.DOTALL)
if not match:
    print('‚ùå Could not find blogPostsData array')
    exit(1)

array_content = match.group(1)

# Split posts by language using a state machine
posts = {
    'en': [],
    'ru': [],
    'de': [],
    'fr': [],
    'es': []
}

current_post = []
brace_depth = 0
in_post = False
in_string = False
string_char = None

lines = array_content.split('\n')

for line in lines:
    # Track brace depth while respecting strings
    for i, char in enumerate(line):
        # Handle strings
        if char in ['"', "'", '`'] and (i == 0 or line[i-1] != '\\'):
            if not in_string:
                in_string = True
                string_char = char
            elif char == string_char:
                in_string = False
                string_char = None

        # Count braces outside of strings
        if not in_string:
            if char == '{':
                brace_depth += 1
                if brace_depth == 1 and not in_post:
                    in_post = True
                    current_post = [line]
                    break
            elif char == '}':
                brace_depth -= 1
                if brace_depth == 0 and in_post:
                    current_post.append(line)
                    post_text = '\n'.join(current_post)

                    # Extract language
                    lang_match = re.search(r"language:\s*'([a-z]{2})'", post_text)
                    if lang_match:
                        lang = lang_match.group(1)
                        if lang in posts:
                            posts[lang].append(post_text.strip())

                    in_post = False
                    current_post = []
                    break

    if in_post and line not in current_post:
        current_post.append(line)

# Create output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Write files
languages = ['en', 'ru', 'de', 'fr', 'es']
stats = {}

for lang in languages:
    lang_posts = posts[lang]
    count = len(lang_posts)

    if count == 0:
        print(f'‚ö†Ô∏è  {lang.upper()}: No posts found')
        continue

    # Format posts with proper indentation
    posts_content = ',\n\n'.join([f'  {post}' for post in lang_posts])

    file_content = f"""import {{ BlogPost }} from '../../types/blog';

/**
 * Blog posts for {lang.upper()} language
 * Auto-generated by scripts/split-blog-posts.py
 * Generated on {datetime.utcnow().isoformat()}Z
 *
 * This file is lazily loaded for better mobile performance
 */

const blogPosts{lang.upper()}: BlogPost[] = [
{posts_content}
];

export default blogPosts{lang.upper()};
"""

    output_file = os.path.join(OUTPUT_DIR, f'blogPosts.{lang}.ts')
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(file_content)

    file_size_kb = len(file_content) / 1024
    stats[lang] = {'count': count, 'sizeKB': file_size_kb}

    print(f'‚úÖ {lang.upper()}: {count} posts ‚Üí blogPosts.{lang}.ts ({file_size_kb:.2f} KB)')

# Summary
print('\nüìä Summary:')
print('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ')
total_posts = sum(s['count'] for s in stats.values())
total_size = sum(s['sizeKB'] for s in stats.values())
avg_per_lang = total_size / len(languages)

print(f'Total posts: {total_posts}')
print(f'Total size: {total_size:.2f} KB')
print(f'Avg per language: {avg_per_lang:.2f} KB')
print(f'\n‚ú® Mobile improvement: ~{(total_size - avg_per_lang):.0f} KB saved per page load')
print(f'   (only loads 1 language instead of all {len(languages)})\n')
